---
title: "Benchmarks Analysis"
output: html_document
date: 2025-07-17
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(ggplot2)
library(dplyr)
library(tidyr)
library(readr)
library(FactoMineR)
library(factoextra)
library(Rtsne)
library(cluster)

here::i_am("rsh/inst/benchmarks/analysis/benchmarks.Rmd")

library(here)

geom_mean <- function(xs) {
  exp(mean(log(na.omit(xs))))
}

DEFAULT_WARMUP <- 5
```

```{r load-data}
# Load the benchmark data
bench_rsh <- read_csv(here("rsh", "benchmark-results", "20250716-193400-e53c63d7", "benchmarks.csv"), col_types = cols(timestamp = col_datetime())) |>
    rename(VM=expr)
bench_bc <- read_csv(here("rsh", "benchmark-results", "baseline", "benchmarks.csv"), col_types = cols(timestamp = col_datetime())) |>
    rename(VM=expr)
bc_profiles <- read_csv(here("rsh", "bcprof-results", "merged_output.csv"), col_types = cols(timestamp = col_datetime()))
```


# Description of the benchmarks

There are `r nrow(bench_rsh)` benchmarks in the RSH results and `r nrow(bench_bc)` in the baseline results.


# Speedups

```{r compute-speedup}
compute_mean <- function(bench) bench |>
  group_by(VM, name) |>
  slice(-(1:DEFAULT_WARMUP)) |># remove warmup
  summarize(
    mean_time = mean(time / 1e6)
  )

speedups <- compute_mean(bench_rsh) |> 
    left_join(compute_mean(bench_bc), by = c("name"), suffix = c("_rsh", "_bc")) |>
    group_by(name) |>
    summarize(
      speedup = mean_time_bc / mean_time_rsh
    ) 

speedups
```

```{r summary-speedup}
speedups |>
    summarize(
        mean = geom_mean(speedup),
        median = median(speedup),
        min = min(speedup),
        max = max(speedup),
        sd = sd(speedup)
    ) 
```

# Bytecode profiler 

```{r bytecode}
df <- select(bc_profiles, -param, -commit, -timestamp) |> 
    left_join(speedups, by = "name") |>
    relocate(speedup, .after = name)
knitr::kable(df, digits = 2, caption = "Bytecode profiler results with speedups") 
```


```{r ranking-opcodes}
calculate_percentages <- function(data) {
  # Select only numeric columns
  numeric_cols <- select(data, -opcode)

  # Calculate total for each numeric column
  totals <- colSums(numeric_cols, na.rm = TRUE)

  # Calculate percentages
  data %>%
    mutate(across(-opcode, ~ .x / totals[cur_column()] * 100, .names = "{.col}_pct"))
}

opcode_hits <- select(df, name, matches("^[A-Z0-9_]+$", ignore.case=FALSE)) |>
  pivot_longer(-name, names_to = "opcode", values_to = "hits") |> 
  pivot_wider(names_from = "name", values_from = "hits", values_fill = 0) 
opcode_pcts <- calculate_percentages(opcode_hits)
opcode_pcts |> select(opcode, ends_with("_pct")) |>
  knitr::kable(digits = 2, caption = "Opcode hits percentages")
```

There are `r nrow(opcode_hits)` opcodes in the benchmarks.

Get the geometric mean of opcode percentages: 
```{r opcode-geometric-mean}
opcode_hits |> rowwise(opcode) |>
  summarize(hits = sum(across(everything()))) |>
  ungroup() |>
  mutate(pct = hits / sum(hits) * 100) |>
  arrange(desc(hits)) |>
  mutate(cpct = cumsum(pct)) |>
  knitr::kable(digits = 2, caption = "Geometric mean of opcode percentages")
``` 

What are the most 10 frequent opcodes per benchmark?

```{r top-opcodes}
top_opcodes <- opcode_hits |>
  pivot_longer(
    cols = -opcode,
    names_to = "benchmark",
    values_to = "hits"
  ) |>
  group_by(benchmark) |>
  slice_max(order_by = hits, n = 10, with_ties = FALSE) |>
  ungroup() |>
  distinct(opcode)
top_opcodes |> 
  knitr::kable(digits = 2, caption = "Top 10 opcodes per benchmark")
```

# Clustering benchmarks using the opcode hits 

```{r clustering_prep}
clustering_data <- opcode_hits |>
  tibble::column_to_rownames("opcode") |> 
  as.matrix() |> t()
clustering_data_scaled <- scale(clustering_data)
```

Finding the best number of clusters:

- elbow method:

```{r elbow, fig.width=12, fig.height=12}
fviz_nbclust(clustering_data_scaled, kmeans, method = "wss") +
  labs(title = "Elbow Method for Optimal k")
```

- silhouette method:

```{r silhouette, fig.width=12, fig.height=12}
fviz_nbclust(clustering_data_scaled, kmeans, method = "silhouette") +
  labs(title = "Silhouette Method for Optimal k")
```

- Gap statistic: 

```{r gap_stat, fig.width=12, fig.height=12}
gap_stat <- clusGap(clustering_data_scaled, FUN = kmeans, nstart = 25,
                    K.max = 10, B = 50)
fviz_gap_stat(gap_stat)
```


```{r choose-k}
k <- 10
```

## Hierachical clustering 

```{r hclust, fig.width=12, fig.height=12}
dist_matrix <- dist(clustering_data_scaled, method = "euclidean")
hc <- hclust(dist_matrix, method = "ward.D2")
plot(hc, labels = rownames(clustering_data_scaled), main = "Hierarchical Clustering Dendrogram", cex = 0.7)

clusters <- cutree(hc, k = k)
cluster_df <- data.frame(
  benchmark = rownames(clustering_data_scaled),
  cluster = clusters
)
print(cluster_df)
```

## K-means

The benchmark was designed into 4 different sets. Can we retrieve them using k-means?


```{r kmeans, fig.width=12, fig.height=12}
set.seed(42)
kmeans_result <- kmeans(clustering_data_scaled, centers = k)
df$cluster <- kmeans_result$cluster
fviz_cluster(kmeans_result, data = clustering_data_scaled)
```

## Rtsne 

```{r rtsne, fig.width=12, fig.height=12}
set.seed(123)
tsne <- Rtsne(clustering_data_scaled, perplexity = 3)
plot(tsne$Y, col = kmeans_result$cluster, pch = 19)
text(tsne$Y, labels = rownames(clustering_data_scaled), pos = 3, cex = 0.8)
```

# PCA on opcodes

```{r pca}
pca <- prcomp(select(df, -name), center = TRUE, scale = TRUE)
summary(pca)
```

```{r pca-loadings}
pca$rotation
```

```{r pca-plot, fig.width=12, fig.height=12}
biplot(pca, scale = 0, cex = 0.5, expand=3, xlim= c(-70, 40), ylim = c(-20, 70)) 
```

Using FactorMineR:

```{r pca-facto, fig.width=12, fig.height=12}
pca_fm <- PCA(select(df, name, speedup, matches("^[A-Z0-9_]+$", ignore.case=FALSE)), 
  scale.unit=TRUE, ncp=5, quanti.sup=2, quali.sup=1, graph = FALSE)
#plot.PCA(pca_fm, axes=c(1, 2), choix="var", habillage=1, cex=0.7)
# https://stackoverflow.com/questions/59865922/visualizing-pca-with-large-number-of-variables-in-r-using-ggbiplot
fviz_pca_biplot(pca_fm, repel = TRUE, select.var = list(contrib = 5))
```

# Random forests

```{r random-forest}
library(randomForest)
library(caret)
set.seed(42)
```

```{r datasets}
ind <- sample(2, nrow(df), replace = TRUE, prob = c(0.7, 0.3))
features <- select(df, -name)
train <- features[ind == 1, ]
test <- features[ind == 2, ]
```

```{r rf-model}
rf_model <- randomForest(speedup ~ ., data = train, importance = TRUE, ntree = 1000)
rf_model
```

```{r importance}
imp <- as.data.frame(importance(rf_model)) |>
  arrange(desc(`%IncMSE`))
imp
```

```{r importance-plot,  fig.width=12, fig.height=12}
ImpData <- as.data.frame(importance(rf_model))
ImpData$Var.Names <- row.names(ImpData)

ggplot(ImpData, aes(x=Var.Names, y=`%IncMSE`)) +
  geom_segment( aes(x=Var.Names, xend=Var.Names, y=0, yend=`%IncMSE`), color="skyblue") +
  geom_point(aes(size = IncNodePurity), color="blue", alpha=0.6) +
  expand_limits(x= c(-1, length(levels(ImpData$Var.Names)) + 2)) + 
  theme_light() +
  coord_flip() +
  theme(
    legend.position="bottom",
    panel.grid.major.y = element_blank(),
    panel.border = element_blank(),
    axis.ticks.y = element_blank(),
    axis.text.y = element_text(size = 8), # Adjust the size of the axis text

  )
```

```{r rf-error}
plot(rf_model)
```